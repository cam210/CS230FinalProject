{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"id":"Gk3xOvbKf3SQ"},"outputs":[],"source":["!pip install tensorflow\n","!pip install mediapipe\n","import pandas as pd\n","import cv2\n","import numpy as np\n","import os\n","import pandas as pd\n","import cv2\n","import mediapipe as mp\n","from sklearn.model_selection import train_test_split\n","import tensorflow_hub as hub\n","import tensorflow as tf\n","from tensorflow.keras.models import load_model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kPKeEQMDpeDx"},"outputs":[],"source":["from google.colab import drive\n","drive.mount('/content/drive')\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wSCsm1_T7B3U"},"outputs":[],"source":["i3d_model_url = \"https://tfhub.dev/deepmind/i3d-kinetics-400/1\"\n","i3d_model = hub.load(i3d_model_url)\n","example_input = tf.random.normal([1, 64, 224, 224, 3])\n","output = i3d_model(example_input)\n","print(output.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SS0B-WPOisH2"},"outputs":[],"source":["\n","from tensorflow.keras import layers, models\n","\n","def inception_module(x, filters):\n","\n","    branch_1 = layers.Conv3D(filters[0], kernel_size=(1, 1, 1), padding='same', activation='relu')(x)\n","    branch_2 = layers.Conv3D(filters[1], kernel_size=(1, 1, 1), padding='same', activation='relu')(x)\n","    branch_2 = layers.Conv3D(filters[2], kernel_size=(3, 3, 3), padding='same', activation='relu')(branch_2)\n","    branch_3 = layers.Conv3D(filters[3], kernel_size=(1, 1, 1), padding='same', activation='relu')(x)\n","    branch_3 = layers.Conv3D(filters[4], kernel_size=(5, 5, 5), padding='same', activation='relu')(branch_3)\n","    branch_4 = layers.MaxPooling3D(pool_size=(3, 3, 3), strides=(1, 1, 1), padding='same')(x)\n","    branch_4 = layers.Conv3D(filters[5], kernel_size=(1, 1, 1), padding='same', activation='relu')(branch_4)\n","\n","    # Concatenate all branches\n","    x = layers.concatenate([branch_1, branch_2, branch_3, branch_4], axis=-1)\n","    return x\n","\n","def I3D_model(input_shape=(16, 64, 64, 3), num_classes=2):\n","    inputs = layers.Input(shape=input_shape)\n","\n","    x = layers.Conv3D(64, kernel_size=(7, 7, 7), strides=(2, 2, 2), padding='same', activation='relu')(inputs)\n","    x = layers.MaxPooling3D(pool_size=(1, 3, 3), strides=(1, 2, 2), padding='same')(x)\n","\n","    x = layers.Conv3D(64, kernel_size=(1, 1, 1), padding='same', activation='relu')(x)\n","    x = layers.Conv3D(192, kernel_size=(3, 3, 3), padding='same', activation='relu')(x)\n","    x = layers.MaxPooling3D(pool_size=(1, 3, 3), strides=(1, 2, 2), padding='same')(x)\n","\n","    x = inception_module(x, [64, 96, 128, 16, 32, 32])\n","    x = inception_module(x, [128, 128, 192, 32, 96, 64])\n","    x = layers.MaxPooling3D(pool_size=(3, 3, 3), strides=(2, 2, 2), padding='same')(x)\n","\n","    x = inception_module(x, [192, 96, 208, 16, 48, 64])\n","    x = inception_module(x, [160, 112, 224, 24, 64, 64])\n","    x = inception_module(x, [128, 128, 256, 24, 64, 64])\n","    x = inception_module(x, [112, 144, 288, 32, 64, 64])\n","    x = inception_module(x, [256, 160, 320, 32, 128, 128])\n","    x = layers.MaxPooling3D(pool_size=(2, 2, 2), strides=(2, 2, 2), padding='same')(x)\n","\n","    x = inception_module(x, [256, 160, 320, 32, 128, 128])\n","    x = inception_module(x, [384, 192, 384, 48, 128, 128])\n","\n","    x = layers.GlobalAveragePooling3D()(x)\n","    x = layers.Dropout(0.4)(x)\n","    outputs = layers.Dense(num_classes, activation='softmax')(x)\n","    model = models.Model(inputs, outputs)\n","    return model\n","\n","\n","input_shape = (16, 64, 64, 3)  # Example shape for input (16 frames, 64x64 resolution, 3 channels)\n","num_classes = 2\n","model = I3D_model(input_shape=input_shape, num_classes=num_classes)\n","\n","\n","model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n","model.summary()\n","\n","\n","print(\"Num GPUs Available:\", len(tf.config.list_physical_devices('GPU')))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5upvH2ItqgIF"},"outputs":[],"source":["\n","def create_annotations_csv(dataset_dir, output_csv):\n","    data = []\n","\n","    # Define label mapping\n","    labels = {\"Healthy\": 0, \"Injured\": 1}\n","\n","    # Traverse through the 'healthy' and 'injured' directories\n","    for label_name, label_value in labels.items():\n","        label_dir = os.path.join(dataset_dir, label_name)\n","        for video_file in os.listdir(label_dir):\n","            if video_file.endswith('.mp4'):\n","                video_path = os.path.join(label_dir, video_file)\n","                data.append([video_path, label_value])\n","\n","    # Create a DataFrame and save it as a CSV\n","    df = pd.DataFrame(data, columns=[\"filepath\", \"label\"])\n","    df.to_csv(output_csv, index=False)\n","    print(f\"Annotation CSV created at {output_csv}\")\n","\n","# Path to your dataset directory and desired CSV output path\n","dataset_dir = '/content/drive/My Drive/Final_Dataset'\n","output_csv = os.path.join(dataset_dir, 'annotations.csv')\n","\n","# Create the annotation CSV\n","create_annotations_csv(dataset_dir, output_csv)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"k3dQPJTYYjwf"},"outputs":[],"source":["\n","\n","\n","data = pd.read_csv('/content/drive/My Drive/Final_Dataset/annotations.csv')\n","print(data['label'].value_counts())\n","\n","\n","train_dev_data, test_data = train_test_split(\n","    data, test_size=0.2, stratify=data['label'], random_state=42\n",")\n","\n","\n","train_data, dev_data = train_test_split(\n","    train_dev_data, test_size=0.25, stratify=train_dev_data['label'], random_state=42\n",")\n","\n","# Check class distribution in each set\n","print(\"Train set class distribution:\\n\", train_data['label'].value_counts())\n","print(\"Dev set class distribution:\\n\", dev_data['label'].value_counts())\n","print(\"Test set class distribution:\\n\", test_data['label'].value_counts())\n","\n","train_data.to_csv('/content/drive/My Drive/Final_Dataset/train.csv', index=False)\n","dev_data.to_csv('/content/drive/My Drive/Final_Dataset/dev.csv', index=False)\n","test_data.to_csv('/content/drive/My Drive/Final_Dataset/test.csv', index=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"luqCqlTjVOv5"},"outputs":[],"source":["\n","\n","def preprocess_video(video_path, num_frames=16, frame_size=(64, 64)):\n","    \"\"\"\n","    Preprocess a video by resizing frames and reducing the number of frames.\n","\n","    Arguments:\n","    video_path -- Path to the video file.\n","    num_frames -- Number of frames to sample from the video.\n","    frame_size -- Resolution to resize frames (width, height).\n","\n","    Returns:\n","    video_tensor -- A numpy array of shape (num_frames, frame_size[0], frame_size[1], 3).\n","    \"\"\"\n","    cap = cv2.VideoCapture(video_path)\n","    frames = []\n","    frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n","\n","    # Calculate frame sampling step to evenly sample num_frames from the video\n","    step = max(1, frame_count // num_frames)\n","\n","    for i in range(num_frames):\n","        frame_index = i * step\n","        cap.set(cv2.CAP_PROP_POS_FRAMES, frame_index)  # Move to the selected frame\n","        ret, frame = cap.read()\n","\n","        if not ret:\n","            break\n","\n","        # Resize the frame to the specified size\n","        frame = cv2.resize(frame, frame_size)\n","        frames.append(frame)\n","\n","    cap.release()\n","\n","    # If the video has fewer frames than num_frames, pad with black frames\n","    while len(frames) < num_frames:\n","        frames.append(np.zeros((frame_size[1], frame_size[0], 3), dtype=np.uint8))\n","\n","    # Normalize pixel values to [0, 1]\n","    video_tensor = np.array(frames, dtype=np.float32) / 255.0\n","    return video_tensor\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9wYtVKVrYoY3"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"id":"NuxLax0dd4TB"},"outputs":[],"source":["\n","\n","def extract_pose_data_from_video(video_path, num_keypoints=33):\n","    \"\"\"\n","    Extracts pose keypoints from a video using MediaPipe Pose.\n","\n","    Arguments:\n","    video_path -- Path to the input video.\n","    num_keypoints -- Number of keypoints expected from MediaPipe Pose.\n","\n","    Returns:\n","    pose_data -- A list of pose keypoints for each frame.\n","    \"\"\"\n","    mp_pose = mp.solutions.pose\n","    pose = mp_pose.Pose(static_image_mode=False, min_detection_confidence=0.5, min_tracking_confidence=0.5)\n","    cap = cv2.VideoCapture(video_path)\n","    pose_data = []\n","\n","    while cap.isOpened():\n","        ret, frame = cap.read()\n","        if not ret:\n","            break\n","\n","        # Convert the frame to RGB\n","        image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n","\n","        # Process the frame to get pose landmarks\n","        results = pose.process(image)\n","\n","        if results.pose_landmarks:\n","            # Extract the pose landmarks (x, y, z coordinates)\n","            frame_data = []\n","            for landmark in results.pose_landmarks.landmark:\n","                frame_data.extend([landmark.x, landmark.y, landmark.z])\n","\n","            # Append the frame's data to the dataset\n","            pose_data.append(frame_data)\n","        else:\n","            # If no pose detected, append a vector of zeros\n","            pose_data.append([0] * num_keypoints * 3)\n","\n","    cap.release()\n","    return pose_data\n","\n","def process_excel_files(input_folder, output_folder, num_keypoints=33):\n","    \"\"\"\n","    Processes all Excel files in the input folder, extracts pose keypoints, and saves results to output folder.\n","\n","    Arguments:\n","    input_folder -- Path to the folder containing Excel files with video paths.\n","    output_folder -- Path to save processed Excel files with pose keypoints.\n","    num_keypoints -- Number of keypoints expected from MediaPipe Pose.\n","    \"\"\"\n","    os.makedirs(output_folder, exist_ok=True)\n","\n","    for excel_file in os.listdir(input_folder):\n","        if excel_file.endswith('.xlsx') or excel_file.endswith('.xls'):\n","            input_path = os.path.join(input_folder, excel_file)\n","            print(f\"Processing {excel_file}...\")\n","\n","            # Load the Excel file\n","            df = pd.read_excel(input_path)\n","\n","            # Check if there is a 'path' column with video paths\n","            if 'path' not in df.columns:\n","                print(f\"Skipping {excel_file}: No 'path' column found.\")\n","                continue\n","\n","            all_pose_data = []\n","            for _, row in df.iterrows():\n","                video_path = row['path']\n","                label = row.get('label', None)  # Optional label column\n","\n","                if os.path.exists(video_path):\n","                    pose_data = extract_pose_data_from_video(video_path, num_keypoints)\n","                    for frame_data in pose_data:\n","                        if label is not None:\n","                            all_pose_data.append([video_path, label] + frame_data)\n","                        else:\n","                            all_pose_data.append([video_path] + frame_data)\n","                else:\n","                    print(f\"Video not found: {video_path}\")\n","\n","            # Save the pose data to a new Excel file\n","            columns = ['path'] + (['label'] if 'label' in df.columns else []) + \\\n","                      [f'keypoint_{i}_{axis}' for i in range(num_keypoints) for axis in ['x', 'y', 'z']]\n","            output_df = pd.DataFrame(all_pose_data, columns=columns)\n","\n","            output_file = os.path.join(output_folder, f\"processed_{excel_file}\")\n","            output_df.to_excel(output_file, index=False)\n","            print(f\"Saved processed data to {output_file}\")\n","\n","\n","process_excel_files(input_folder, output_folder)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WNH0J1coY8Zo"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MsYkj4WIVsUv"},"outputs":[],"source":["def data_generator(file_paths, labels, preprocess_func, batch_size=16):\n","    \"\"\"\n","    Generator to yield batches of preprocessed data and labels.\n","\n","    Arguments:\n","    file_paths -- List of file paths.\n","    labels -- Corresponding list of labels.\n","    preprocess_func -- Function to preprocess a single file.\n","    batch_size -- Number of samples per batch.\n","\n","    Yields:\n","    batch_x -- Batch of preprocessed data.\n","    batch_y -- Batch of corresponding labels.\n","    \"\"\"\n","    num_samples = len(file_paths)\n","    while True:\n","        for i in range(0, num_samples, batch_size):\n","            batch_paths = file_paths[i:i + batch_size]\n","            batch_labels = labels[i:i + batch_size]\n","\n","            # Preprocess each file\n","            batch_x = [preprocess_func(file_path) for file_path in batch_paths]\n","            batch_x = tf.stack(batch_x)  # Stack into a tensor\n","\n","            batch_y = tf.convert_to_tensor(batch_labels)\n","\n","            yield batch_x, batch_y\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"aTE23fGkMNdb"},"outputs":[],"source":["model_path = '/content/drive/My Drive/Final_Dataset/saved_model/my_model.h5'\n","model= load_model(model_path)\n","\n","# Confirm the model is loaded\n","model.summary()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FXedO7e7ZCIX"},"outputs":[],"source":["\n","data_directory = '/content/drive/My Drive/Final_Dataset'\n","\n","# Load training and validation file paths and labels\n","train_df = pd.read_csv(os.path.join(data_directory, 'train.csv'))\n","dev_df = pd.read_csv(os.path.join(data_directory, 'dev.csv'))\n","\n","train_paths = train_df['filepath'].tolist()\n","train_labels = train_df['label'].tolist()\n","dev_paths = dev_df['filepath'].tolist()\n","dev_labels = dev_df['label'].tolist()\n","\n","test_df = pd.read_csv(os.path.join(data_directory, 'test.csv'))\n","test_paths = test_df['filepath'].tolist()\n","test_labels = test_df['label'].tolist()\n","test_gen = data_generator(test_paths, test_labels, preprocess_video, batch_size=16)\n","\n","# Create data generators\n","train_gen = data_generator(train_paths, train_labels, preprocess_video, batch_size=16)\n","dev_gen = data_generator(dev_paths, dev_labels, preprocess_video, batch_size=16)\n","save_model_path = '/content/drive/My Drive/Final_Dataset/saved_model/my_model.h5'\n","# Train the model\n","history = model.fit(\n","    train_gen,\n","    steps_per_epoch=15,\n","    validation_data=dev_gen,\n","    validation_steps=5,\n","    epochs=100\n",")\n","model.save(save_model_path)\n","print(f\"Model saved to: {save_model_path}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2uuCGRlyOzY5"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"zQgNZWo2aB0d"},"outputs":[],"source":["data_directory = '/content/drive/My Drive/Final_Dataset'\n","\n","test_steps = len(test_paths) // 16\n","test_pred = model.predict(test_gen)\n","test_loss, test_accuracy = model.evaluate(test_data, test_pred )\n","print(f\"Test Loss: {test_loss}, Test Accuracy: {test_accuracy}\")"]},{"cell_type":"markdown","metadata":{"id":"jIZC6EviknCc"},"source":["# New Section"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","machine_shape":"hm","provenance":[],"mount_file_id":"1hdt84rq7UtegtTRENzgeU6gJe2bwTuKF","authorship_tag":"ABX9TyMoHXqAjyXFWTMP8v4iAdly"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}