{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","gpuType":"T4","mount_file_id":"1eSVZVCKrgUiHmzwkvW5Y7lSiQbSfplJd","authorship_tag":"ABX9TyOV1nvFW4/Nf3Kbay9wJy6I"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"id":"1T_hOohNNaHr"},"outputs":[],"source":["!pip install tensorflow\n","!pip install mediapipe\n","import pandas as pd\n","import cv2\n","import numpy as np\n","import os\n","import pandas as pd\n","import cv2\n","import mediapipe as mp\n","from sklearn.model_selection import train_test_split\n","from tensorflow.keras import regularizers\n","from sklearn.metrics import classification_report, accuracy_score, precision_score, recall_score, f1_score\n","from tensorflow.keras.models import load_model"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')\n","\n","\n"],"metadata":{"id":"5b9TN70FOD4r"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","\n","mp_pose = mp.solutions.pose\n","pose = mp_pose.Pose(static_image_mode=False, min_detection_confidence=0.5, min_tracking_confidence=0.5)\n","\n","# Function to extract pose keypoints from a video\n","def process_video(video_path, num_frames=32):\n","    cap = cv2.VideoCapture(video_path)\n","    keypoints = []\n","    frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n","    step = max(1, frame_count // num_frames)\n","\n","    for i in range(num_frames):\n","        cap.set(cv2.CAP_PROP_POS_FRAMES, i * step)\n","        ret, frame = cap.read()\n","        if not ret:\n","            break\n","\n","        # Convert frame to RGB for MediaPipe\n","        image_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n","        results = pose.process(image_rgb)\n","\n","        # Extract pose keypoints if detected\n","        if results.pose_landmarks:\n","            frame_keypoints = []\n","            for landmark in results.pose_landmarks.landmark:\n","                frame_keypoints.extend([landmark.x, landmark.y, landmark.z, landmark.visibility])\n","            keypoints.append(frame_keypoints)\n","        else:\n","            keypoints.append([0] * (33 * 4))  # Pad with zeros if no keypoints detected\n","\n","    cap.release()\n","\n","    # Ensure all videos have the same number of frames\n","    while len(keypoints) < num_frames:\n","        keypoints.append([0] * (33 * 4))  # Pad with zeros\n","\n","    return np.array(keypoints)\n","\n","\n","def create_dataset_with_progress(video_dir, label, num_frames=32):\n","    data = []\n","    video_files = [f for f in os.listdir(video_dir) if f.endswith('.mp4')]  # List of video files\n","    total_videos = min(len(video_files), max_videos)  # Limit to max_videos\n","\n","    for idx, video_file in enumerate(video_files[:total_videos], start=1):\n","        video_path = os.path.join(video_dir, video_file)\n","        keypoints = process_video(video_path, num_frames)\n","        data.append({'keypoints': keypoints, 'label': label})\n","\n","        # Print progress\n","        print(f\"Processed {idx}/{total_videos} videos in directory '{video_dir}'\")\n","\n","    return data\n","\n","# Paths to healthy and injured videos\n","healthy_dir = '/content/drive/My Drive/Final_Dataset/Healthy'\n","injured_dir = '/content/drive/My Drive/Final_Dataset/Injured'\n","\n","# Create datasets with progress tracking, limited to 750 videos each\n","print(\"Processing Healthy videos...\")\n","healthy_data = create_dataset_with_progress(healthy_dir, label=0)\n","\n","print(\"\\nProcessing Injured videos...\")\n","injured_data = create_dataset_with_progress(injured_dir, label=1)\n","\n","# Combine and save the dataset\n","all_data = healthy_data + injured_data\n","np.save('/content/drive/My Drive/Final_Dataset/pose_dataset.npy', all_data)\n","print(\"\\nPose dataset saved successfully!\")\n","\n","\n"],"metadata":{"id":"BH0wlnkwO3_o"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["data = np.load('/content/drive/My Drive/Final_Dataset/pose_dataset_5000.npy', allow_pickle=True)\n","\n","# Prepare features and labels\n","X = np.array([item['keypoints'] for item in data])  # Shape: (num_samples, num_frames, 33*4)\n","y = np.array([item['label'] for item in data])      # Shape: (num_samples,)\n","\n","# Split into training, validation, and test sets\n","from sklearn.model_selection import train_test_split\n","\n","# First, split data into train+val and test sets\n","X_temp, X_test, y_temp, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","\n","# Next, split the remaining train+val set into training and validation sets\n","X_train, X_val, y_train, y_val = train_test_split(X_temp, y_temp, test_size=0.25, random_state=42)  # 0.25 x 0.8 = 0.2\n","\n","# Reshape input for the model\n","X_train = X_train.reshape(X_train.shape[0], X_train.shape[1], 33, 4)  # (samples, frames, landmarks, features)\n","X_val = X_val.reshape(X_val.shape[0], X_val.shape[1], 33, 4)\n","X_test = X_test.reshape(X_test.shape[0], X_test.shape[1], 33, 4)\n"],"metadata":{"id":"RN-iglRzaibk","executionInfo":{"status":"ok","timestamp":1733077135373,"user_tz":300,"elapsed":4314,"user":{"displayName":"Max Prentis","userId":"07674852681910313530"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["import tensorflow as tf\n","from tensorflow.keras import layers, models\n","\n","def build_pose_model(input_shape=(32, 33, 4), num_classes=2):\n","    model = models.Sequential()\n","\n","    # Flatten input for fully connected layers\n","    model.add(layers.Flatten(input_shape=input_shape))\n","\n","    # Fully Connected Layers\n","    model.add(layers.Dense(512, activation='relu'))\n","    model.add(layers.Dropout(0.5))  # Dropout to prevent overfitting\n","    model.add(layers.Dense(256, activation='relu'))\n","    model.add(layers.Dropout(0.5))\n","    model.add(layers.Dense(128, activation='relu'))\n","    model.add(layers.Dense(num_classes, activation='softmax'))  # Output layer for classification\n","\n","    return model\n","\n","# Build and compile the model\n","input_shape = (32, 33 * 4)  # 32 frames, flattened (33 keypoints * 4 features)\n","num_classes = 2\n","model = build_pose_model(input_shape=input_shape, num_classes=num_classes)\n","\n","model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n","model.summary()\n","\n"],"metadata":{"id":"mgUxUOxbcIEE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def build_rnn_model(input_shape=(32, 33, 4), num_classes=2):\n","    model = models.Sequential()\n","\n","    # Flatten spatial dimensions (33 keypoints x 4 features per frame)\n","    model.add(layers.TimeDistributed(layers.Flatten(), input_shape=input_shape))\n","\n","    # LSTM layers to process temporal data\n","    model.add(layers.LSTM(128, return_sequences=True))\n","    model.add(layers.LSTM(64))\n","\n","    # Fully connected layers\n","    model.add(layers.Dense(128, activation='relu'))\n","    model.add(layers.Dropout(0.5))\n","    model.add(layers.Dense(num_classes, activation='softmax'))  # Output layer\n","\n","    return model\n","\n","# Instantiate and compile the model\n","input_shape = (32, 33, 4)  # 32 frames, 33 keypoints, 4 features (x, y, z, visibility)\n","num_classes = 2\n","model = build_rnn_model(input_shape=input_shape, num_classes=num_classes)\n","\n","model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n","model.summary()"],"metadata":{"id":"FKo31dN5nIcP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model_path = '/content/drive/My Drive/Final_Dataset/pose_model.h5'\n","#model_path = '/content/drive/My Drive/Final_Dataset/pose_model_rnn.h5'\n","model= load_model(model_path)\n","\n","# Confirm the model is loaded\n","model.summary()"],"metadata":{"id":"o2XPVjFj1DGi"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Train the model\n","history = model.fit(\n","    X_train, y_train,\n","    validation_data=(X_val, y_val),\n","    epochs=250,\n","    batch_size=16\n",")\n","\n","# Save the trained model\n","model.save('/content/drive/My Drive/Final_Dataset/pose_model.h5')\n","print(\"Model saved!\")\n"],"metadata":{"id":"OSs7ig_XcKsq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","\n","\n","# Evaluate the model on the test set\n","print(\"Evaluating on test set...\")\n","test_loss, test_accuracy = model.evaluate(X_test, y_test, batch_size=16)\n","print(f\"Test Loss: {test_loss:.4f}\")\n","print(f\"Test Accuracy: {test_accuracy:.4f}\")\n","\n","# Predict class probabilities and labels\n","y_pred_probs = model.predict(X_test)\n","y_pred = np.argmax(y_pred_probs, axis=1)\n","\n","# Compute precision, recall, and accuracy\n","print(\"\\nClassification Metrics:\")\n","print(classification_report(y_test, y_pred))\n","\n","overall_accuracy = accuracy_score(y_test, y_pred)\n","precision = precision_score(y_test, y_pred, average='weighted')\n","recall = recall_score(y_test, y_pred, average='weighted')\n","\n","print(f\"Overall Accuracy: {overall_accuracy:.4f}\")\n","print(f\"Precision: {precision:.4f}\")\n","print(f\"Recall: {recall:.4f}\")"],"metadata":{"id":"PcIJjqYhgXc_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Assuming X_test and y_test are preprocessed and ready\n","test_loss, test_accuracy = model.evaluate(X_test, y_test)\n","print(f\"Test Loss: {test_loss}, Test Accuracy: {test_accuracy}\")\n","\n","# Make predictions\n","y_pred = (model.predict(X_test) > 0.5).astype(\"int32\")\n","y_pred_binary = np.argmax(y_pred, axis=1)\n","y_test_binary = y_test.ravel()\n","\n","# Evaluate performance using metrics like precision, recall, F1-score\n","from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, roc_curve\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","\n","# Classification metrics\n","#print(classification_report(y_test, y_pred))\n","\n","# Confusion matrix\n","conf_matrix = confusion_matrix(y_test, y_pred_binary)\n","sns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap=\"Blues\")\n","plt.title(\"Confusion Matrix\")\n","plt.xlabel(\"Predicted\")\n","plt.ylabel(\"Actual\")\n","plt.show()\n","\n","\n","# ROC Curve\n","y_prob = model.predict(X_test)[:, 1]  # Get probabilities for positive class\n","auc = roc_auc_score(y_test, y_prob)\n","fpr, tpr, _ = roc_curve(y_test, y_prob)\n","\n","plt.plot(fpr, tpr, label=f\"AUC = {auc:.2f}\")\n","plt.xlabel(\"False Positive Rate\")\n","plt.ylabel(\"True Positive Rate\")\n","plt.title(\"ROC Curve\")\n","plt.legend()\n","plt.show()"],"metadata":{"id":"O_QiAsu_7cRV"},"execution_count":null,"outputs":[]}]}